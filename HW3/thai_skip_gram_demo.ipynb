{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Word Embedding Demo\n",
    "\n",
    "In this demo, we will guide you through the basic steps for creating word representations using skip-gram neural network architecture.\n",
    "\n",
    "In your homework, you will work on the skip-gram neural network architecture for Word2Vec. You will be using Keras to train your model. \n",
    "\n",
    "The sample code for skip-gram model is given. Your job is to incorporate the tokenizer model that you created in HomeWork-1 to tokenize raw text and turn it into word vectors.\n",
    "\n",
    "You must complete the following tasks:\n",
    "1. Read/clean text files\n",
    "2. Indexing (Assign a number to each word)\n",
    "3. Create skip-grams (inputs for your model)\n",
    "4. Create the skip-gram neural network model\n",
    "5. Visualization\n",
    "6. Evaluation (Using pre-trained, not using pre-trained)\n",
    "    (classify topic from 4 best categories)  (compare)\n",
    "\n",
    "\n",
    "This notebook assumes you have already installed Tensorflow and Keras with python3 and had GPU enabled. If you run this exercise on GCloud using the provided disk image you are all set.\n",
    "\n",
    "As a reminder,\n",
    "\n",
    "### Don't forget to shut down your instance on Gcloud when you are not using it ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read/clean text files\n",
    "\n",
    "The given code can be used to processed the pre-tokenzied text file from the wikipedia corpus. In your homework, you must replace those text files with raw text files.  You must use your own tokenizer to process your text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 1: read the wikipedia text file\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "#with open(cwd+\"/corpora/wiki/thwiki_chk.txt\") as f:\n",
    "with open(\"/home/ekapolc/corpora/wiki/thwiki_chk.txt\") as f:\n",
    "    #the delimiter is one or more whitespace characters\n",
    "    input_text = re.compile(r\"\\s+\").split(f.read()) \n",
    "    #exclude an empty string from our input\n",
    "    input_text = [word for word in input_text if word != ''] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total word count: 36349066\n"
     ]
    }
   ],
   "source": [
    "print(\"total word count:\", len(input_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2: Indexing (Assign a number to each word)\n",
    "\n",
    "The given code below generates an indexed dataset(each word is represented by a number), a dictionary, a reversed dictionary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Your job is to set a threshold for rare words and replace them with \"UNK\"\n",
    "\n",
    "+ Please tell how you choose a number for your threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ที่', 950006), ('ใน', 897329), ('เป็น', 726847), ('และ', 668116), ('การ', 619128), ('มี', 536738), ('ของ', 532237), ('ได้', 508117), (')', 359576), ('\"', 357830)]\n"
     ]
    }
   ],
   "source": [
    "#step 2:Build dictionary and build a dataset(replace each word with its index)\n",
    "def create_index(input_text):\n",
    "    \n",
    "    words = [word for word in input_text ]\n",
    "    word_count = list()\n",
    "    #use set and len to get the number of unique words\n",
    "    word_count.extend(collections.Counter(words).most_common(len(set(words))))\n",
    "    #include a token for unknown word\n",
    "    word_count.append((\"UNK\",0))\n",
    "    #print out 10 most frequent words\n",
    "    print(word_count[:10])\n",
    "    dictionary = dict()\n",
    "    for word in word_count:\n",
    "        dictionary[word[0]] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    data = list()\n",
    "    for word in input_text:\n",
    "        data.append(dictionary[word])\n",
    "\n",
    "    return data,dictionary, reverse_dictionary\n",
    "\n",
    "dataset,dictionary, reverse_dictionary=create_index(input_text)\n",
    "del input_text #just to clear up some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output sample (dataset): [228, 207, 2452, 572, 14, 1828, 7172, 3124, 680, 23]\n",
      "output sample (dictionary): {'ใจกลางเปียงยาง': 618855, 'Nuevo': 295169, 'เกียรติบันลือ': 295167, 'ฮัมเดน': 127222, 'บ็อบ': 10183, 'เอี่ยมเนตร': 295163, 'เรียนทุ่งช้าง': 295164, 'โมบลี': 295165, 'จากรุก': 295168, 'Bickenhill': 295166}\n",
      "output sample (reverse dictionary): {0: 'ที่', 1: 'ใน', 2: 'เป็น', 3: 'และ', 4: 'การ', 5: 'มี', 6: 'ของ', 7: 'ได้', 8: ')', 9: '\"'}\n"
     ]
    }
   ],
   "source": [
    "print(\"output sample (dataset):\",dataset[:10])\n",
    "print(\"output sample (dictionary):\",{k: dictionary[k] for k in list(dictionary)[:10]})\n",
    "print(\"output sample (reverse dictionary):\",{k: reverse_dictionary[k] for k in list(reverse_dictionary)[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701355"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary) #number of unique words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Step3: Create skip-grams (inputs for your model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7172, 3124], [7172, 1828], [7172, 278989], [7172, 475628]] [1, 1, 0, 0]\n",
      "วิกิ มีเดีย 1\n",
      "วิกิ มูลนิธิ 1\n",
      "วิกิ โกโกส 0\n",
      "วิกิ 戒幢律寺 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-37a3d28314cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreverse_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcouples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreverse_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcouples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Step 3: Create data samples \n",
    "vocab_size = len(dictionary)\n",
    "skip_window = 1       # How many words to consider left and right.\n",
    "\n",
    "sample_set= dataset[:10]\n",
    "sampling_table = sequence.make_sampling_table(vocab_size)\n",
    "couples, labels = skipgrams(sample_set, vocab_size, window_size=skip_window, sampling_table=sampling_table)\n",
    "word_target, word_context = zip(*couples)\n",
    "word_target = np.array(word_target, dtype=\"int32\")\n",
    "word_context = np.array(word_context, dtype=\"int32\")\n",
    "\n",
    "print(couples, labels)\n",
    "\n",
    "for i in range(8):\n",
    "    print(reverse_dictionary[couples[i][0]],reverse_dictionary[couples[i][1]],labels[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Step 4: create the skip-gram model\n",
    "![Skip-gram model](https://raw.githubusercontent.com/ekapolc/nlp_course/master/HW3/skipgram.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1, 32)         22443360    input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 1, 32)         22443360    input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dot_1 (Dot)                      (None, 1, 1)          0           embedding_1[0][0]                \n",
      "                                                                   embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 1)             0           dot_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 1)             0           reshape_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 44,886,720\n",
      "Trainable params: 44,886,720\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#reference:  https://github.com/nzw0301/keras-examples/blob/master/Skip-gram-with-NS.ipynb\n",
    "\n",
    "\n",
    "dim_embedddings = 32 #embedding dimension\n",
    "V= len(dictionary) #Vocab size\n",
    "\n",
    "#step1: select the embedding of the target word from W\n",
    "w_inputs = Input(shape=(1, ), dtype='int32')\n",
    "w = Embedding(V, dim_embedddings)(w_inputs)\n",
    "\n",
    "#step2: select the embedding of the context word from C\n",
    "c_inputs = Input(shape=(1, ), dtype='int32')\n",
    "c  = Embedding(V, dim_embedddings)(c_inputs)\n",
    "\n",
    "#step3: compute the dot product:w*c\n",
    "o = Dot(axes=2)([w, c])\n",
    "o = Reshape((1,), input_shape=(1, 1))(o)\n",
    "\n",
    "#step4: normailize dot products into probability\n",
    "o = Activation('sigmoid')(o)\n",
    "\n",
    "SkipGram = Model(inputs=[w_inputs, c_inputs], outputs=o)\n",
    "SkipGram.summary()\n",
    "SkipGram.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train for 5 epoch\n",
    "#it will take roughly 3-4 hours for each epoch\n",
    "# PRO TIPS: you don't have to spend too much time training for your homework, you are allowed to do it on a smaller corpus\n",
    "for _ in range(5):\n",
    "    prev_i=0\n",
    "    #it is likely that your GPU won't be able to handle 36 million words\n",
    "    #just do it 100000 words at a time\n",
    "    \n",
    "    for i in range(len(dataset)//100000):\n",
    "        #generate skipgrams\n",
    "        data, labels = skipgrams(sequence=dataset[prev_i:i+100000], vocabulary_size=V, window_size=2, negative_samples=4.)\n",
    "        x = [np.array(x) for x in zip(*data)]\n",
    "        y = np.array(labels, dtype=np.int32)\n",
    "        if x:\n",
    "            loss = SkipGram.train_on_batch(x, y)\n",
    "        \n",
    "        print(loss,i*100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SkipGram.save_weights('/data/my_skipgram32_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[]\n\t [[Node: Adam/lr/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Adam/lr\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Adam/lr, Adam/lr/initial_value)]]\n\nCaused by op 'Adam/lr/Assign', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-addf063b42bc>\", line 24, in <module>\n    SkipGram.compile(loss='binary_crossentropy', optimizer='adam')\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/engine/training.py\", line 624, in compile\n    self.optimizer = optimizers.get(optimizer)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/optimizers.py\", line 717, in get\n    return deserialize(config)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/optimizers.py\", line 689, in deserialize\n    printable_module_name='optimizer')\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/utils/generic_utils.py\", line 141, in deserialize_keras_object\n    return cls.from_config(config['config'])\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/optimizers.py\", line 127, in from_config\n    return cls(**config)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/optimizers.py\", line 406, in __init__\n    self.lr = K.variable(lr, name='lr')\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 316, in variable\n    v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 199, in __init__\n    expected_shape=expected_shape)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 320, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/ops/state_ops.py\", line 274, in assign\n    validate_shape=validate_shape)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 43, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[]\n\t [[Node: Adam/lr/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Adam/lr\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Adam/lr, Adam/lr/initial_value)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[]\n\t [[Node: Adam/lr/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Adam/lr\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Adam/lr, Adam/lr/initial_value)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-37238ec33172>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSkipGram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/data/my_skipgram32_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m   2617\u001b[0m             \u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2618\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2619\u001b[1;33m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'close'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m   3093\u001b[0m                              ' elements.')\n\u001b[0;32m   3094\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3095\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2191\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2192\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2193\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[0m_initialize_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[1;34m()\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muninitialized_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[]\n\t [[Node: Adam/lr/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Adam/lr\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Adam/lr, Adam/lr/initial_value)]]\n\nCaused by op 'Adam/lr/Assign', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-addf063b42bc>\", line 24, in <module>\n    SkipGram.compile(loss='binary_crossentropy', optimizer='adam')\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/engine/training.py\", line 624, in compile\n    self.optimizer = optimizers.get(optimizer)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/optimizers.py\", line 717, in get\n    return deserialize(config)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/optimizers.py\", line 689, in deserialize\n    printable_module_name='optimizer')\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/utils/generic_utils.py\", line 141, in deserialize_keras_object\n    return cls.from_config(config['config'])\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/optimizers.py\", line 127, in from_config\n    return cls(**config)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/optimizers.py\", line 406, in __init__\n    self.lr = K.variable(lr, name='lr')\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 316, in variable\n    v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 199, in __init__\n    expected_shape=expected_shape)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 320, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/ops/state_ops.py\", line 274, in assign\n    validate_shape=validate_shape)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 43, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ekapolc/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[]\n\t [[Node: Adam/lr/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Adam/lr\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Adam/lr, Adam/lr/initial_value)]]\n"
     ]
    }
   ],
   "source": [
    "SkipGram.load_weights('/data/my_skipgram32_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get weight of the embedding layer\n",
    "final_embeddings=SkipGram.get_weights()[0]\n",
    "print(final_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Visualize the embeddings\n",
    "\n",
    "t-Distributed Stochastic Neighbor Embedding (t-SNE) is a technique for dimensionality reduction that is suited for the visualization of high-dimensional datasets. You don't need to understand t-SNE to complete this course, but it is a very powerful tool of visualizing your word vectors. You can read more about t-SNE here: https://lvdmaaten.github.io/tsne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Visualize the embeddings.\n",
    "# Function to draw visualization of distance between embeddings.\n",
    "#reference: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py\n",
    "def plot_with_labels(low_dim_embs, labels, filename=\"tsne_plot.png\"):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "    fp = mpl.font_manager.FontProperties(family='TH Sarabun New')\n",
    "    plt.figure(figsize=(15, 15))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                     xy=(x, y),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom',\n",
    "                     fontproperties=fp)\n",
    "    plt.show()\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=2500)\n",
    "plot_only = 500 #only top 500 words\n",
    "low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
    "labels = [reverse_dictionary[i] for i in range(plot_only)]\n",
    "plot_with_labels(low_dim_embs, labels)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization: Tensorboard\n",
    "\n",
    "http://bit.ly/2s0SNHl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#VISUALIZATION ON TENSORBOARD\n",
    "#reference: https://github.com/keras-team/keras/pull/5247\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "\n",
    "#you need two files to represent data on tensorboard projector\n",
    "#1 weights\n",
    "#2 metadata \n",
    "import csv\n",
    "with open('/data/weights.tsv', 'w') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "    writer.writerows(final_embeddings[:10000])\n",
    "\n",
    "with open('/data/metadata.tsv', 'w') as tsvfile:\n",
    "    for i in range(10000):\n",
    "        tsvfile.write(reverse_dictionary[i]+\"\\n\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Evaluation\n",
    "\"Of course the most important evaluation metric for vector models is extrinsic evaluation\n",
    "on tasks; adding them as features into any NLP task and seeing whether this\n",
    "improves performance.\n",
    "\n",
    "Nonetheless it is useful to have intrinsic evaluations. The most common metric\n",
    "is to test their performance on similarity, and in particular on computing the\n",
    "correlation between an algorithm’s word similarity scores and word similarity ratings\n",
    "assigned by humans\" - Dan Jarafsky (reference: https://web.stanford.edu/~jurafsky/slp3/15.pdf)\n",
    "\n",
    "Cosine similarity is an important metric for measuring similarity between words. In this demo, we will guide you through some examples that you might be able to use to evaluate your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03682636]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#sci-kit learns provide a simple module that you can use to calculate cosine similarity\n",
    "print(cosine_similarity(final_embeddings[dictionary[\"ไง\"]].reshape(1, -1), final_embeddings[dictionary[\"ชวน\"]].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.58669341,  0.54148865, -0.60007215,  0.64678901,  0.70417434,\n",
       "        0.62284714, -0.62249666,  0.54382384,  0.7081365 ,  0.62931299,\n",
       "       -0.69667792,  0.71439731,  0.69069183, -0.59075159, -0.62458253,\n",
       "        0.54854584, -0.65565348,  0.54297113, -0.56244928, -0.57262307,\n",
       "       -0.69184369, -0.6548087 ,  0.55907404,  0.57358831,  0.58288246,\n",
       "        0.6439184 , -0.59740955,  0.6719209 , -0.56868756, -0.64249682,\n",
       "        0.64433581,  0.66374224], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings[dictionary[\"ประเทศไทย\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ดี\n",
      "กระสุน\n",
      "ยืน\n",
      "จริง\n",
      "ก้าว\n",
      "ครั้งนี้\n",
      "ซึ่งตั้ง\n",
      "ภาพยนตร์แอนิเมชัน\n",
      "ดวงจันทร์\n",
      "ซื่อ\n",
      "วิกิพีเดีย\n",
      "แม่น้ำเจ้าพระยา\n",
      "ถือกำเนิด\n",
      "ทุ\n",
      "เศร้า\n",
      "จังหวัดราชบุรี\n",
      "1903\n",
      "สูท\n",
      "ติง\n",
      "ลิเบีย\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "#scipy also provides you with a module that you can use to compare your target words against all the words in your corpus\n",
    "v = final_embeddings[dictionary[\"ดี\"]].reshape(1, -1)\n",
    "#just compare with top 10000 words....\n",
    "all_dist = scipy.spatial.distance.cdist(final_embeddings[:10000], v, 'cosine').reshape(-1)\n",
    "# get 20 nearest vector \n",
    "# argpartition can get top twenty very quickly, but they are not sorted\n",
    "idx =np.argpartition(all_dist, 20)[:20]\n",
    "#sort\n",
    "idx = idx[np.argsort(all_dist[idx[:20]])]\n",
    "for i in idx:\n",
    "    print(reverse_dictionary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to do any visualization you must reduce the dimension of your word vectors to 2D or 3D...\n",
    "tsne2 = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "plot_only = 10000#only top 10000 words\n",
    "low_dim_embs2 = tsne2.fit_transform(final_embeddings[:plot_only, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99145126]]\n",
      "[[-0.19122621]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(final_embeddings[dictionary[\"ประเทศไทย\"]].reshape(1, -1), final_embeddings[dictionary[\"ประเทศญี่ปุ่น\"]].reshape(1, -1)))\n",
    "print(cosine_similarity(final_embeddings[dictionary[\"ประเทศไทย\"]].reshape(1, -1), final_embeddings[dictionary[\"ไส้กรอก\"]].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAANSCAYAAADPuZfpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAKAhMQcAANCQmAMAAGhIzAEAADT0/wEtMVegN3RATAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67211ac208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f671f9eef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing the famous \"king-male+female=queen\" \n",
    "labels = [reverse_dictionary[i] for i in range(plot_only)]\n",
    "word_list = ['พระราชา','ชาย','พระราชินี','หญิง']\n",
    "idx_list = []\n",
    "for word in word_list:\n",
    "    idx_list.append(labels.index(word))\n",
    "word_plot = low_dim_embs2[idx_list]\n",
    "plot_with_labels(word_plot,word_list,filename=\"queen_king.png\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
